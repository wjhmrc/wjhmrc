<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>WJHMRC</title>
  
  <subtitle>做一个有情怀的计算机人</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://wjhmrc.top/"/>
  <updated>2018-08-14T15:44:24.256Z</updated>
  <id>http://wjhmrc.top/</id>
  
  <author>
    <name>缪若尘</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>机器学习算法实现——K-Means聚类（Python）</title>
    <link href="http://wjhmrc.top/2018/06/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E2%80%94%E2%80%94K-Means%E8%81%9A%E7%B1%BB%EF%BC%88Python%EF%BC%89/"/>
    <id>http://wjhmrc.top/2018/06/02/机器学习算法实现——K-Means聚类（Python）/</id>
    <published>2018-06-02T03:05:12.000Z</published>
    <updated>2018-08-14T15:44:24.256Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-原理"><a href="#1-原理" class="headerlink" title="1. 原理"></a>1. 原理</h2><p>给定样本集,“K均值”(K-means)算法针对聚类所得簇划分最小化平方误差 </p><p><img src="data:image/png;base64,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" alt="math"></p><p> 其中是簇的均值向量.直观来看,公式在一定程度上刻画了簇内样本围绕簇均值向量的紧密程度E值越小则簇内样本相似度越高. </p><p>公式并不容易找到它的最优解,需要考察样本集D所有可能的簇划分这是一个NP难问题.因此k均值算法采用了贪心策略通过迭代优化来近似求解公式.</p><h2 id="2-代码"><a href="#2-代码" class="headerlink" title="2. 代码"></a>2. 代码</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"># coding=utf-8</span><br><span class="line">import random</span><br><span class="line">import numpy</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">start = time.clock()</span><br><span class="line"></span><br><span class="line"># 准备数据集</span><br><span class="line">dataSet = []  # 数据集</span><br><span class="line">file = open(&quot;数据集.txt&quot;)</span><br><span class="line"></span><br><span class="line">for line in file.readlines():</span><br><span class="line">    lineArr = line.strip().split(&apos;\t&apos;)</span><br><span class="line">    dataSet.append([float(lineArr[0]), float(lineArr[1])])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># K-Means算法函数</span><br><span class="line">def KMeans(dataSet, k):</span><br><span class="line">    firstVector = random.sample(dataSet, k)  # 准备初始均值向量</span><br><span class="line">    c_last = []</span><br><span class="line">    mTimes = 1000  # 最大迭代次数</span><br><span class="line">    for turns in range(mTimes):</span><br><span class="line">        c = [[] for i in range(k)]  # 本轮聚类的结果集</span><br><span class="line"></span><br><span class="line">        distance = [[1 for i in range(k)] for i in range(len(dataSet))]  # 记录每个点到每个聚类中心的距离</span><br><span class="line"></span><br><span class="line">        for i in range(len(dataSet)):</span><br><span class="line">            for j in range(k):</span><br><span class="line">                # 计算欧氏距离</span><br><span class="line">                length_x_sq = pow(dataSet[i][0] - firstVector[j][0], 2)</span><br><span class="line">                length_y_sq = pow(dataSet[i][1] - firstVector[j][1], 2)</span><br><span class="line">                distance_temp = numpy.sqrt(length_x_sq + length_y_sq)</span><br><span class="line">                distance[i][j] = distance_temp</span><br><span class="line"></span><br><span class="line">        print(distance)</span><br><span class="line">        for i in range(len(dataSet)):</span><br><span class="line">            minValue = min(distance[i])</span><br><span class="line">            c[distance[i].index(minValue)].append(dataSet[i])</span><br><span class="line"></span><br><span class="line">        print(c)</span><br><span class="line">        # 更新均值向量</span><br><span class="line">        j = 0</span><br><span class="line">        while j &lt; k:</span><br><span class="line">            firstVector[j][0] = sum(c[j][0]) / len(c[j][0])</span><br><span class="line">            firstVector[j][1] = sum(c[j][1]) / len(c[j][1])</span><br><span class="line">            j += 1</span><br><span class="line"></span><br><span class="line">        # 如果结果集不再更新，证明已经收敛，退出循环</span><br><span class="line"></span><br><span class="line">        if c == c_last:</span><br><span class="line">            print(turns)</span><br><span class="line">            break</span><br><span class="line">        c_last = c</span><br><span class="line"></span><br><span class="line">    return c</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">result = KMeans(dataSet, 4)</span><br><span class="line"># print(len(result[0]))</span><br><span class="line"># print(len(result[1]))</span><br><span class="line"># print(len(result[2]))</span><br><span class="line"># print(len(result[3]))</span><br><span class="line">markers = [&apos;x&apos;, &apos;*&apos;, &apos;+&apos;, &apos;^&apos;, &apos;o&apos;]</span><br><span class="line">for i in range(4):</span><br><span class="line">    for j in range(len(result[i])):</span><br><span class="line">        plt.scatter(result[i][j][0], result[i][j][1], s=60, marker=markers[i], c=&apos;b&apos;, alpha=0.5)</span><br><span class="line">plt.title(&apos; &apos;)</span><br><span class="line">plt.show()</span><br><span class="line">plt.savefig(&apos;KMeans.png&apos;)</span><br><span class="line"></span><br><span class="line">elapsed = (time.clock() - start)</span><br><span class="line">print(elapsed)</span><br></pre></td></tr></table></figure><h2 id="3-验证"><a href="#3-验证" class="headerlink" title="3. 验证"></a>3. 验证</h2><p>试验运行了多次,聚类效果还可以,但不是十分完美.效果如图: </p><p><img src="data:image/png;base64,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" alt="KMeans"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-原理&quot;&gt;&lt;a href=&quot;#1-原理&quot; class=&quot;headerlink&quot; title=&quot;1. 原理&quot;&gt;&lt;/a&gt;1. 原理&lt;/h2&gt;&lt;p&gt;给定样本集,“K均值”(K-means)算法针对聚类所得簇划分最小化平方误差 &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;dat
      
    
    </summary>
    
      <category term="机器学习" scheme="http://wjhmrc.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Machine Learning" scheme="http://wjhmrc.top/tags/Machine-Learning/"/>
    
  </entry>
  
</feed>
